import os
import sys
import joblib
import numpy as np
import pandas as pd
import xgboost as xgb
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt
import seaborn as sns

# Add PYTHONPATH
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from src.preprocess import load_data, fit_transformers, preprocess_for_training

def analyze_model_improvements():
    print("Loading data and model...")
    # Load data and model
    df = load_data()
    model = xgb.Booster()
    model.load_model("model/xgb_model.json")
    ohe = joblib.load("model/onehot_encoder.joblib")
    scaler = joblib.load("model/standard_scaler.joblib")
    feature_names = joblib.load("model/feature_names.joblib")
    categorical_features = joblib.load("model/categorical_features.joblib")
    numerical_features = joblib.load("model/numerical_features.joblib")
    
    print("Preprocessing data...")
    # Preprocess data
    X, y, _ = preprocess_for_training(df, ohe, scaler, 
                                    categorical_features=categorical_features,
                                    numerical_features=numerical_features)
    
    # Split data
    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)
    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)
    
    print("\nAnalyzing model improvements...")
    # 1. Ph√¢n t√≠ch Feature Importance
    analyze_feature_importance(model, feature_names, df)
    
    # 2. Ph√¢n t√≠ch c√°c ng∆∞·ª°ng threshold
    analyze_thresholds(model, X_test, y_test)
    
    # 3. ƒê·ªÅ xu·∫•t feature m·ªõi
    suggest_new_features(df)

def analyze_feature_importance(model, feature_names, df):
    """Ph√¢n t√≠ch chi ti·∫øt v·ªÅ t·∫ßm quan tr·ªçng c·ªßa c√°c feature"""
    importance = model.get_score(importance_type='gain')
    importance = {feature_names[int(k.replace('f', ''))]: v for k, v in importance.items()}
    importance = dict(sorted(importance.items(), key=lambda x: x[1], reverse=True))
    
    print("\nüìä Feature Importance Analysis:")
    print("\nTop 5 features quan tr·ªçng nh·∫•t:")
    for i, (feature, score) in enumerate(list(importance.items())[:5], 1):
        print(f"{i}. {feature}: {score:.4f}")
    
    print("\nBottom 5 features √≠t quan tr·ªçng nh·∫•t:")
    for i, (feature, score) in enumerate(list(importance.items())[-5:], 1):
        print(f"{i}. {feature}: {score:.4f}")
    
    # Ch·ªâ l·∫•y c√°c c·ªôt s·ªë ƒë·ªÉ t√≠nh correlation
    df_numeric = df.select_dtypes(include=[np.number]).copy()
    # ƒê·∫£m b·∫£o c·ªôt approved l√† s·ªë
    if 'approved' in df.columns:
        df_numeric['approved'] = pd.to_numeric(df['approved'], errors='coerce')
    print("\nCorrelation v·ªõi target:")
    print(df_numeric.corr()['approved'].sort_values(ascending=False))

def analyze_thresholds(model, X_test, y_test):
    """Ph√¢n t√≠ch c√°c ng∆∞·ª°ng threshold kh√°c nhau"""
    y_pred_proba = model.predict(xgb.DMatrix(X_test))
    
    thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]
    print("\nüìà Threshold Analysis:")
    print("\nThreshold | Precision | Recall | F1")
    print("-" * 40)
    
    for threshold in thresholds:
        y_pred = (y_pred_proba > threshold).astype(int)
        precision = precision_score(y_test, y_pred)
        recall = recall_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)
        print(f"{threshold:.1f} | {precision:.4f} | {recall:.4f} | {f1:.4f}")

def suggest_new_features(df):
    """ƒê·ªÅ xu·∫•t c√°c feature m·ªõi d·ª±a tr√™n ph√¢n t√≠ch d·ªØ li·ªáu"""
    print("\nüí° Feature Engineering Suggestions:")
    
    # 1. T·ª∑ l·ªá kho·∫£n vay/thu nh·∫≠p
    if 'requested_loan_amount' in df.columns and 'monthly_net_income' in df.columns:
        print("1. T·ª∑ l·ªá kho·∫£n vay/thu nh·∫≠p h√†ng th√°ng")
        print("   - C√≥ th·ªÉ l√† ch·ªâ s·ªë quan tr·ªçng ƒë·ªÉ ƒë√°nh gi√° kh·∫£ nƒÉng tr·∫£ n·ª£")
    
    # 2. T∆∞∆°ng t√°c gi·ªØa ƒëi·ªÉm t√≠n d·ª•ng v√† thu nh·∫≠p
    if 'credit_score' in df.columns and 'monthly_net_income' in df.columns:
        print("2. T∆∞∆°ng t√°c gi·ªØa ƒëi·ªÉm t√≠n d·ª•ng v√† thu nh·∫≠p")
        print("   - C√≥ th·ªÉ t·∫°o feature m·ªõi: credit_score * monthly_net_income")
    
    # 3. Ph√¢n nh√≥m thu nh·∫≠p
    if 'monthly_net_income' in df.columns:
        print("3. Ph√¢n nh√≥m thu nh·∫≠p")
        print("   - T·∫°o c√°c nh√≥m thu nh·∫≠p: th·∫•p, trung b√¨nh, cao")
    
    # 4. T∆∞∆°ng t√°c gi·ªØa m·ª•c ƒë√≠ch vay v√† kho·∫£n vay
    if 'loan_purpose_code' in df.columns and 'requested_loan_amount' in df.columns:
        print("4. T∆∞∆°ng t√°c gi·ªØa m·ª•c ƒë√≠ch vay v√† kho·∫£n vay")
        print("   - Ph√¢n t√≠ch m·ªëi quan h·ªá gi·ªØa m·ª•c ƒë√≠ch vay v√† s·ªë ti·ªÅn vay")
    
    # 5. Th·ªùi gian l√†m vi·ªác
    if 'employment_status' in df.columns:
        print("5. Th·ªùi gian l√†m vi·ªác")
        print("   - Th√™m feature v·ªÅ th·ªùi gian l√†m vi·ªác t·∫°i c√¥ng ty hi·ªán t·∫°i")

if __name__ == "__main__":
    analyze_model_improvements() 