import sys, os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import pandas as pd
import numpy as np
import sqlalchemy
import sklearn
from sqlalchemy import text
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from scipy import sparse

# Use sparse matrices for OneHotEncoder
if sklearn.__version__ >= "1.2":
    ohe = OneHotEncoder(sparse_output=True, handle_unknown='ignore')
else:
    ohe = OneHotEncoder(sparse=True, handle_unknown='ignore')

# -----------------------------
# üì• Load d·ªØ li·ªáu t·ª´ MySQL
# -----------------------------
def load_data():
    df = pd.read_csv("data/loan_applications_35.csv")
    print("\nTh√¥ng tin DataFrame:")
    print(f"Shape: {df.shape}")
    print("\nC√°c c·ªôt trong DataFrame:")
    print(df.columns.tolist())
    print("\nM·∫´u d·ªØ li·ªáu (5 d√≤ng ƒë·∫ßu):")
    print(df.head())
    return df


# -----------------------------
# üéØ Sinh th√™m ƒë·∫∑c tr∆∞ng m·ªõi (n·∫øu c·∫ßn)
# -----------------------------
### C√°i n√†y b·ªè nh√© #### a ƒë·ªãnh x·ª≠ l√≠ c√°i n√†y ch·ªâ c√≥ 2 bi·∫øn Indpendent v√† Family th√¥i 
def process_marital_status(df: pd.DataFrame) -> pd.DataFrame:
    """
    X·ª≠ l√Ω marital_status b·∫±ng c√°ch g·ªôp nh√≥m v√† c√¢n b·∫±ng l·∫°i m·∫´u
    """
    # G·ªôp c√°c nh√≥m t∆∞∆°ng t·ª± nh∆∞ng gi·ªØ nguy√™n t√™n c·ªôt marital_status
    marital_mapping = {
        'Single': 'Independent',
        'Married': 'Family',
        'Divorced': 'Independent',
        'Widowed': 'Independent',
        'Separated': 'Independent',
        'Common-Law': 'Independent'
    }
    
    # T·∫°o c·ªôt t·∫°m th·ªùi ƒë·ªÉ l∆∞u nh√≥m
    df['_marital_status_group'] = df['marital_status'].map(marital_mapping)
    
    # T√≠nh to√°n tr·ªçng s·ªë cho t·ª´ng nh√≥m
    marital_weights = {
        'Independent': 1.0,  # Nh√≥m c∆° b·∫£n
        'Family': 1.0       # C√¢n b·∫±ng v·ªõi nh√≥m c∆° b·∫£n
    }
    
    # √Åp d·ª•ng tr·ªçng s·ªë v√†o c·ªôt g·ªëc
    df['marital_status'] = df['_marital_status_group'].map(marital_mapping)
    
    # X√≥a c·ªôt t·∫°m th·ªùi
    df = df.drop('_marital_status_group', axis=1)
    
    return df

def add_derived_features(df: pd.DataFrame) -> pd.DataFrame:
    # t√≠nh th√™m T·ª∑ l·ªá ti·∫øt ki·ªám
    df['savings_ratio'] = (df['monthly_gross_income'] - df['cash_outflow_avg']) / df['monthly_gross_income']
    
    #  T√≠nh th√™m ƒêi·ªÉm ·ªïn ƒë·ªãnh vi·ªác l√†m
    df['employment_stability_score'] = df['employer_tenure_years'] * 10 + df['address_tenure_years'] * 5
    
    # T√≠nh th√™m ƒêi·ªÉm t√≠n d·ª•ng ƒëi·ªÅu ch·ªânh
    df['adjusted_credit_score'] = df['credit_score'].astype(float)  # Chuy·ªÉn ƒë·ªïi sang float tr∆∞·ªõc
    df.loc[df['active_trade_lines'] < 5, 'adjusted_credit_score'] *= 1.2  # TƒÉng 20% cho ng∆∞·ªùi m·ªõi
    
    # T√≠nh th√™m ƒêi·ªÉm t·ªïng h·ª£p
    df['composite_score'] = (
        df['adjusted_credit_score'] * 0.4 +
        df['employment_stability_score'] * 0.3 +
        df['savings_ratio'] * 0.3
    )
    
    return df


# -----------------------------
# üõ°Ô∏è Rule-based checks cho 35 features
# -----------------------------
def rule_based_checks(df: pd.DataFrame) -> pd.DataFrame:
    # Numeric rules
    assert (df['requested_loan_amount'] >= 8410851).all() and (df['requested_loan_amount'] <= 2995999341).all(), "requested_loan_amount ph·∫£i trong kho·∫£ng [8.4M, 2.99B]"
    assert (df['tenor_requested'] >= 6).all() and (df['tenor_requested'] <= 72).all(), "tenor_requested ph·∫£i trong kho·∫£ng [6, 72] th√°ng"
    assert (df['employer_tenure_years'] >= 0).all() and (df['employer_tenure_years'] <= 37.5).all(), "employer_tenure_years ph·∫£i trong kho·∫£ng [0, 37.5] nƒÉm"
    assert (df['monthly_gross_income'] >= 5000124).all() and (df['monthly_gross_income'] <= 79242217).all(), "monthly_gross_income ph·∫£i trong kho·∫£ng [5M, 79.2M]"
    assert (df['monthly_net_income'] >= 3519761).all() and (df['monthly_net_income'] <= 75241072).all(), "monthly_net_income ph·∫£i trong kho·∫£ng [3.5M, 75.2M]"
    assert (df['dti_ratio'] >= 0).all() and (df['dti_ratio'] <= 1.5).all(), "dti_ratio ph·∫£i trong kho·∫£ng [0, 1.5]"
    assert (df['dependents_count'] >= 0).all() and (df['dependents_count'] <= 6).all(), "dependents_count ph·∫£i trong kho·∫£ng [0, 6]"
    assert (df['credit_score'] >= 277).all() and (df['credit_score'] <= 1041).all(), "credit_score ph·∫£i trong kho·∫£ng [277, 1041]"
    assert (df['active_trade_lines'] >= 0).all() and (df['active_trade_lines'] <= 12).all(), "active_trade_lines ph·∫£i trong kho·∫£ng [0, 12]"
    assert (df['revolving_utilisation'] >= 0).all() and (df['revolving_utilisation'] <= 1).all(), "revolving_utilisation ph·∫£i trong kho·∫£ng [0, 1]"
    assert (df['delinquencies_30d'] >= 0).all() and (df['delinquencies_30d'] <= 5).all(), "delinquencies_30d ph·∫£i trong kho·∫£ng [0, 5]"
    assert (df['avg_account_age_months'] >= 1).all() and (df['avg_account_age_months'] <= 617).all(), "avg_account_age_months ph·∫£i trong kho·∫£ng [1, 617] th√°ng"
    assert (df['hard_inquiries_6m'] >= 0).all() and (df['hard_inquiries_6m'] <= 8).all(), "hard_inquiries_6m ph·∫£i trong kho·∫£ng [0, 8]"
    assert (df['cash_inflow_avg'] >= 85375).all() and (df['cash_inflow_avg'] <= 79242217).all(), "cash_inflow_avg ph·∫£i trong kho·∫£ng [85K, 79.2M]"
    assert (df['cash_outflow_avg'] >= 85531).all() and (df['cash_outflow_avg'] <= 75241072).all(), "cash_outflow_avg ph·∫£i trong kho·∫£ng [85K, 75.2M]"
    assert (df['min_monthly_balance'] >= 0).all() and (df['min_monthly_balance'] <= 50000000).all(), "min_monthly_balance ph·∫£i trong kho·∫£ng [0, 50M]"
    assert df['application_time_of_day'].isin(['Morning (6-12)', 'Afternoon (12-18)', 'Night (0-6)', 'Evening (18-24)']).all(), "application_time_of_day ph·∫£i l√† m·ªôt trong c√°c gi√° tr·ªã: Morning, Afternoon, Night, Evening"
    assert (df['ip_mismatch_score'] >= 0).all() and (df['ip_mismatch_score'] <= 0.75).all(), "ip_mismatch_score ph·∫£i trong kho·∫£ng [0, 0.75]"
    assert (df['id_doc_age_years'] >= 0).all() and (df['id_doc_age_years'] <= 20).all(), "id_doc_age_years ph·∫£i trong kho·∫£ng [0, 20] nƒÉm"
    assert (df['income_gap_ratio'] >= -0.3).all() and (df['income_gap_ratio'] <= 0.3).all(), "income_gap_ratio ph·∫£i trong kho·∫£ng [-0.3, 0.3]"
    assert (df['address_tenure_years'] >= 0).all() and (df['address_tenure_years'] <= 30).all(), "address_tenure_years ph·∫£i trong kho·∫£ng [0, 30] nƒÉm"
    assert (df['industry_unemployment_rate'] >= 0.01).all() and (df['industry_unemployment_rate'] <= 0.15).all(), "industry_unemployment_rate ph·∫£i trong kho·∫£ng [0.01, 0.15]"
    assert (df['regional_economic_score'] >= 40).all() and (df['regional_economic_score'] <= 100).all(), "regional_economic_score ph·∫£i trong kho·∫£ng [40, 100]"
    assert (df['inflation_rate_yoy'] >= 0).all() and (df['inflation_rate_yoy'] <= 0.12).all(), "inflation_rate_yoy ph·∫£i trong kho·∫£ng [0, 0.12]"
    assert (df['policy_cap_ratio'] >= 0).all() and (df['policy_cap_ratio'] <= 1).all(), "policy_cap_ratio ph·∫£i trong kho·∫£ng [0, 1]"

    # Categorical rules
    assert df['loan_purpose_code'].isin(['EDU', 'AGRI', 'CONSOLIDATION', 'HOME', 'TRAVEL', 'AUTO', 'MED', 'OTHER', 'BUSS', 'PL', 'RENOVATION', 'CREDIT_CARD']).all(), "loan_purpose_code kh√¥ng h·ª£p l·ªá"
    assert df['employment_status'].isin(['Retired', 'Student', 'Full-Time', 'Freelancer', 'Unemployed', 'Self-Employed', 'Seasonal', 'Part-Time', 'Contract']).all(), "employment_status kh√¥ng h·ª£p l·ªá"
    assert df['housing_status'].isin(['Family', 'Company Dorm', 'Mortgage', 'Other', 'Government', 'Own', 'Rent']).all(), "housing_status kh√¥ng h·ª£p l·ªá"
    assert df['educational_level'].isin(['High School', 'Other', 'Below HS', 'Vocational', 'Master', 'MBA', 'Doctorate', 'Associate', 'Bachelor']).all(), "educational_level kh√¥ng h·ª£p l·ªá"
    assert df['marital_status'].isin(['Separated', 'Single', 'Married', 'Common-Law', 'Widowed', 'Divorced']).all(), "marital_status kh√¥ng h·ª£p l·ªá"
    assert df['position_in_company'].isin(['Manager', 'Intern', 'Executive', 'Supervisor', 'Staff', 'Senior Staff', 'Director', 'Owner', 'Senior Mgr']).all(), "position_in_company kh√¥ng h·ª£p l·ªá"

    # Boolean rules
    assert df['thin_file_flag'].isin([0, 1]).all(), "thin_file_flag ph·∫£i l√† 0 ho·∫∑c 1"
    assert df['bankruptcy_flag'].isin([0, 1]).all(), "bankruptcy_flag ph·∫£i l√† 0 ho·∫∑c 1"

    return df


# -----------------------------
# üß† Fit encoder & scaler (ch·ªâ d√πng khi training)
# -----------------------------
def fit_transformers(df: pd.DataFrame):
    df = add_derived_features(df)
    df = rule_based_checks(df)
    
    cat_cols = [
        'loan_purpose_code', 'employment_status', 'housing_status', 'educational_level',
        'marital_status', 'position_in_company', 'applicant_address', 'application_time_of_day'
    ]
    num_cols = [
        'requested_loan_amount', 'tenor_requested', 'employer_tenure_years', 'monthly_gross_income',
        'monthly_net_income', 'dti_ratio', 'dependents_count', 'credit_score',
        'active_trade_lines', 'revolving_utilisation', 'delinquencies_30d', 'avg_account_age_months',
        'hard_inquiries_6m', 'cash_inflow_avg', 'cash_outflow_avg', 'min_monthly_balance',
        'ip_mismatch_score', 'id_doc_age_years', 'income_gap_ratio',
        'address_tenure_years', 'industry_unemployment_rate', 'regional_economic_score', 'inflation_rate_yoy',
        'policy_cap_ratio'
    ]
    bool_cols = ['thin_file_flag', 'bankruptcy_flag']
    ohe = OneHotEncoder(sparse_output=True, handle_unknown='ignore')
    ohe.fit(df[cat_cols])
    scaler = StandardScaler()
    scaler.fit(df[num_cols])
    return ohe, scaler


# -----------------------------
# üìä D√πng khi training
# -----------------------------
def preprocess_for_training(df: pd.DataFrame, ohe: OneHotEncoder, scaler: StandardScaler):
    df = add_derived_features(df)
    df = adjust_weights(df)
    df = apply_compensation_rules(df)
    df = adjust_approval_threshold(df)
    df = rule_based_checks(df)
    df = process_marital_status(df)
    
    cat_cols = [
        'loan_purpose_code', 'employment_status', 'housing_status', 'educational_level',
        'marital_status', 'position_in_company', 'applicant_address', 'application_time_of_day'
    ]
    num_cols = [
        'requested_loan_amount', 'tenor_requested', 'employer_tenure_years', 'monthly_gross_income',
        'monthly_net_income', 'dti_ratio', 'dependents_count', 'credit_score',
        'active_trade_lines', 'revolving_utilisation', 'delinquencies_30d', 'avg_account_age_months',
        'hard_inquiries_6m', 'cash_inflow_avg', 'cash_outflow_avg', 'min_monthly_balance',
        'ip_mismatch_score', 'id_doc_age_years', 'income_gap_ratio',
        'address_tenure_years', 'industry_unemployment_rate', 'regional_economic_score', 'inflation_rate_yoy',
        'policy_cap_ratio'
    ]
    bool_cols = ['thin_file_flag', 'bankruptcy_flag']
    
    # Convert boolean to int8
    for col in bool_cols:
        df[col] = df[col].astype(np.int8)
    
    # Transform categorical features to sparse matrix
    cat_vals = ohe.transform(df[cat_cols])
    cat_feature_names = ohe.get_feature_names_out(cat_cols)
    
    # Transform numeric features and convert to float32 to save memory
    num_vals = scaler.transform(df[num_cols]).astype(np.float32)
    num_df = pd.DataFrame(num_vals, columns=num_cols, index=df.index)
    
    # Convert boolean features to int8
    bool_df = df[bool_cols].astype(np.int8)
    
    # Combine all features
    X = sparse.hstack([sparse.csr_matrix(num_df), sparse.csr_matrix(bool_df), cat_vals])
    
    # Create feature names list
    feature_names = num_cols + bool_cols + cat_feature_names.tolist()
    
    # Check if approved column exists
    if 'approved' not in df.columns:
        print("\nC√°c c·ªôt hi·ªán c√≥ trong DataFrame:")
        print(df.columns.tolist())
        print("\nVui l√≤ng ƒë·∫£m b·∫£o c·ªôt 'approved' t·ªìn t·∫°i trong d·ªØ li·ªáu ƒë·∫ßu v√†o.")
        raise ValueError("C·ªôt 'approved' kh√¥ng t·ªìn t·∫°i trong d·ªØ li·ªáu. Vui l√≤ng ki·ªÉm tra l·∫°i d·ªØ li·ªáu ƒë·∫ßu v√†o.")
    
    y = df['approved']
    if y.isna().any():
        print("\nS·ªë l∆∞·ª£ng gi√° tr·ªã NA trong c·ªôt 'approved':", y.isna().sum())
        raise ValueError("C·ªôt 'approved' ch·ª©a gi√° tr·ªã NA. Vui l√≤ng ki·ªÉm tra v√† x·ª≠ l√Ω d·ªØ li·ªáu thi·∫øu.")
    
    # Convert approved to int8 (0/1)
    y = y.astype(np.int8)
    
    return X, y, feature_names


# -----------------------------
# ‚öôÔ∏è D√πng trong API khi ƒë√£ c√≥ ohe + scaler
# -----------------------------
def preprocess_for_inference(df: pd.DataFrame, ohe: OneHotEncoder, scaler: StandardScaler, feature_cols: list):
    df = add_derived_features(df)
    df = adjust_weights(df)
    df = apply_compensation_rules(df)
    df = adjust_approval_threshold(df)
    df = rule_based_checks(df)
    
    cat_cols = [
        'loan_purpose_code', 'employment_status', 'housing_status', 'educational_level',
        'marital_status', 'position_in_company', 'applicant_address', 'application_time_of_day'
    ]
    num_cols = [
        'requested_loan_amount', 'tenor_requested', 'employer_tenure_years', 'monthly_gross_income',
        'monthly_net_income', 'dti_ratio', 'dependents_count', 'credit_score',
        'active_trade_lines', 'revolving_utilisation', 'delinquencies_30d', 'avg_account_age_months',
        'hard_inquiries_6m', 'cash_inflow_avg', 'cash_outflow_avg', 'min_monthly_balance',
        'ip_mismatch_score', 'id_doc_age_years', 'income_gap_ratio',
        'address_tenure_years', 'industry_unemployment_rate', 'regional_economic_score', 'inflation_rate_yoy',
        'policy_cap_ratio'
    ]
    bool_cols = ['thin_file_flag', 'bankruptcy_flag']
    
    # Convert boolean to int8
    for col in bool_cols:
        df[col] = df[col].astype(np.int8)
    
    # Transform categorical features to sparse matrix
    cat_vals = ohe.transform(df[cat_cols])
    cat_feature_names = ohe.get_feature_names_out(cat_cols)
    
    # Transform numeric features and convert to float32
    num_vals = scaler.transform(df[num_cols]).astype(np.float32)
    num_df = pd.DataFrame(num_vals, columns=num_cols, index=df.index)
    
    # Convert boolean features to int8
    bool_df = df[bool_cols].astype(np.int8)
    
    # Combine all features
    X_new = sparse.hstack([sparse.csr_matrix(num_df), sparse.csr_matrix(bool_df), cat_vals])
    
    # Create feature names list
    feature_names = num_cols + bool_cols + cat_feature_names.tolist()
    
    # Convert to dense matrix only for the required features
    X_new = X_new.todense()
    X_new = pd.DataFrame(X_new, columns=feature_names)
    X_new = X_new[feature_cols]
    
    #################ƒëo·∫°n n√†y c√≥ th·ªÉ custom l·∫°i n√©####################
    return X_new, generate_customer_advice(df)

def adjust_weights(df: pd.DataFrame) -> pd.DataFrame:
    # Nh√≥m 1: Ng∆∞·ªùi m·ªõi b·∫Øt ƒë·∫ßu (th·ªùi gian l√†m vi·ªác < 3 nƒÉm)
    mask_new = df['employer_tenure_years'] < 3
    df.loc[mask_new, 'composite_score'] *= 1.2  # TƒÉng 20% ƒëi·ªÉm
    
    # Nh√≥m 2: Ng∆∞·ªùi c√≥ thu nh·∫≠p th·∫•p nh∆∞ng ·ªïn ƒë·ªãnh
    mask_stable = (df['monthly_gross_income'] < 30000000) & (df['employer_tenure_years'] > 5)
    df.loc[mask_stable, 'composite_score'] *= 1.15  # TƒÉng 15% ƒëi·ªÉm
    
    # Nh√≥m 3: Ng∆∞·ªùi c√≥ t√†i s·∫£n th·∫ø ch·∫•p
    mask_collateral = df['housing_status'].isin(['Own', 'Mortgage'])
    df.loc[mask_collateral, 'composite_score'] *= 1.1  # TƒÉng 10% ƒëi·ªÉm
    
    return df

def apply_compensation_rules(df: pd.DataFrame) -> pd.DataFrame:
    # Quy t·∫Øc 1: B√π tr·ª´ cho ng∆∞·ªùi c√≥ l·ªãch s·ª≠ thanh to√°n t·ªët
    good_payment = (df['delinquencies_30d'] == 0) & (df['revolving_utilisation'] < 0.3)
    df.loc[good_payment, 'composite_score'] *= 1.15
    
    # Quy t·∫Øc 2: B√π tr·ª´ cho ng∆∞·ªùi c√≥ tr√¨nh ƒë·ªô cao
    high_education = df['educational_level'].isin(['Master', 'MBA', 'Doctorate'])
    df.loc[high_education, 'composite_score'] *= 1.1
    
    # Quy t·∫Øc 3: B√π tr·ª´ cho ng∆∞·ªùi c√≥ v·ªã tr√≠ c√¥ng vi·ªác cao
    high_position = df['position_in_company'].isin(['Director', 'Senior Mgr', 'Owner'])
    df.loc[high_position, 'composite_score'] *= 1.1
    
    return df

def adjust_approval_threshold(df: pd.DataFrame) -> pd.DataFrame:
    # Ng∆∞·ª°ng c∆° b·∫£n
    base_threshold = 0.5
    
    # ƒêi·ªÅu ch·ªânh ng∆∞·ª°ng theo nh√≥m
    df['approval_threshold'] = base_threshold
    
    # Gi·∫£m ng∆∞·ª°ng cho ng∆∞·ªùi m·ªõi b·∫Øt ƒë·∫ßu c√≥ ti·ªÅm nƒÉng
    new_potential = (df['employer_tenure_years'] < 3) & (df['educational_level'].isin(['Master', 'MBA', 'Doctorate']))
    df.loc[new_potential, 'approval_threshold'] *= 0.9
    
    # Gi·∫£m ng∆∞·ª°ng cho ng∆∞·ªùi c√≥ thu nh·∫≠p th·∫•p nh∆∞ng ·ªïn ƒë·ªãnh
    stable_low_income = (df['monthly_gross_income'] < 30000000) & (df['employer_tenure_years'] > 5)
    df.loc[stable_low_income, 'approval_threshold'] *= 0.95
    
    return df

######################### T·∫°o g·ª£i √Ω, l·ª£i khuy√™n ############################################# C√°i n√†y c√≥ th·ªÉ xem t√≠nh h·ª£p v·ªõi b√™n em


def generate_customer_advice(df: pd.DataFrame) -> dict:
    """
    T·∫°o l·ªùi t∆∞ v·∫•n th√¢n thi·ªán cho kh√°ch h√†ng d·ª±a tr√™n h·ªì s∆° c·ªßa h·ªç
    """
    advice = {
        "strengths": [],
        "improvements": [],
        "suggestions": [],
        "next_steps": []
    }
    
    # Ph√¢n t√≠ch ƒëi·ªÉm m·∫°nh
    if df['credit_score'].iloc[0] >= 800:
        advice["strengths"].append("ƒêi·ªÉm t√≠n d·ª•ng c·ªßa b·∫°n r·∫•t t·ªët, ƒë√¢y l√† m·ªôt l·ª£i th·∫ø l·ªõn")
    elif df['credit_score'].iloc[0] >= 700:
        advice["strengths"].append("ƒêi·ªÉm t√≠n d·ª•ng c·ªßa b·∫°n ·ªü m·ª©c kh√° t·ªët")
        
    if df['employer_tenure_years'].iloc[0] >= 5:
        advice["strengths"].append(f"B·∫°n c√≥ {df['employer_tenure_years'].iloc[0]} nƒÉm kinh nghi·ªám l√†m vi·ªác, th·ªÉ hi·ªán s·ª± ·ªïn ƒë·ªãnh t·ªët")
        
    if df['educational_level'].iloc[0] in ['Master', 'MBA', 'Doctorate']:
        advice["strengths"].append(f"Tr√¨nh ƒë·ªô {df['educational_level'].iloc[0]} c·ªßa b·∫°n l√† m·ªôt ƒëi·ªÉm c·ªông l·ªõn")
        
    if df['position_in_company'].iloc[0] in ['Director', 'Senior Mgr', 'Owner']:
        advice["strengths"].append(f"V·ªã tr√≠ {df['position_in_company'].iloc[0]} th·ªÉ hi·ªán nƒÉng l·ª±c v√† tr√°ch nhi·ªám cao")
        
    if df['housing_status'].iloc[0] in ['Own', 'Mortgage']:
        advice["strengths"].append("Vi·ªác s·ªü h·ªØu nh√† ri√™ng l√† m·ªôt ƒëi·ªÉm c·ªông v·ªÅ t√†i s·∫£n th·∫ø ch·∫•p")
        
    # Ph√¢n t√≠ch ƒëi·ªÉm c·∫ßn c·∫£i thi·ªán
    if df['active_trade_lines'].iloc[0] < 5:
        advice["improvements"].append("L·ªãch s·ª≠ t√≠n d·ª•ng c·ªßa b·∫°n c√≤n kh√° m·ªèng, n√™n x√¢y d·ª±ng th√™m c√°c m·ªëi quan h·ªá t√≠n d·ª•ng")
        
    if df['revolving_utilisation'].iloc[0] > 0.5:
        advice["improvements"].append("T·ª∑ l·ªá s·ª≠ d·ª•ng h·∫°n m·ª©c t√≠n d·ª•ng c·ªßa b·∫°n kh√° cao, n√™n gi·∫£m b·ªõt")
        
    if df['dti_ratio'].iloc[0] > 0.5:
        advice["improvements"].append("T·ª∑ l·ªá n·ª£/thu nh·∫≠p c·ªßa b·∫°n kh√° cao, n√™n gi·∫£m b·ªõt c√°c kho·∫£n n·ª£ hi·ªán t·∫°i")
        
    # ƒê·ªÅ xu·∫•t c·∫£i thi·ªán
    if df['active_trade_lines'].iloc[0] < 5:
        advice["suggestions"].append("C√¢n nh·∫Øc m·ªü th√™m 1-2 th·∫ª t√≠n d·ª•ng v√† s·ª≠ d·ª•ng c√≥ tr√°ch nhi·ªám")
        
    if df['monthly_gross_income'].iloc[0] < 30000000:
        advice["suggestions"].append("C√≥ th·ªÉ c√¢n nh·∫Øc t√¨m ki·∫øm ngu·ªìn thu nh·∫≠p b·ªï sung")
        
    if df['savings_ratio'].iloc[0] < 0.2:
        advice["suggestions"].append("N√™n tƒÉng t·ª∑ l·ªá ti·∫øt ki·ªám l√™n √≠t nh·∫•t 20% thu nh·∫≠p")
        
    # H∆∞·ªõng d·∫´n ti·∫øp theo
    advice["next_steps"].append("Chu·∫©n b·ªã ƒë·∫ßy ƒë·ªß c√°c gi·∫•y t·ªù ch·ª©ng minh thu nh·∫≠p v√† t√†i s·∫£n")
    advice["next_steps"].append("C√¢n nh·∫Øc gi·∫£m b·ªõt s·ªë ti·ªÅn vay ho·∫∑c tƒÉng th·ªùi h·∫°n vay ƒë·ªÉ gi·∫£m √°p l·ª±c tr·∫£ n·ª£")
    advice["next_steps"].append("Li√™n h·ªá v·ªõi chuy√™n vi√™n t∆∞ v·∫•n ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£ chi ti·∫øt h∆°n")
    
    return advice
