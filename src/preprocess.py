import sys, os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import pandas as pd
import numpy as np
import sqlalchemy
import sklearn
from sqlalchemy import text
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from scipy import sparse
from typing import Tuple, List

# Use sparse matrices for OneHotEncoder
if sklearn.__version__ >= "1.2":
    ohe = OneHotEncoder(sparse_output=True, handle_unknown='ignore')
else:
    ohe = OneHotEncoder(sparse=True, handle_unknown='ignore')

# -----------------------------
# üì• Load d·ªØ li·ªáu t·ª´ MySQL
# -----------------------------
def load_data():
    df = pd.read_csv("data/loan100.csv")
    print("\nTh√¥ng tin DataFrame:")
    print(f"Shape: {df.shape}")
    print("\nC√°c c·ªôt trong DataFrame:")
    print(df.columns.tolist())
    print("\nM·∫´u d·ªØ li·ªáu (5 d√≤ng ƒë·∫ßu):")
    print(df.head())
    return df


# -----------------------------
# üéØ Sinh th√™m ƒë·∫∑c tr∆∞ng m·ªõi (n·∫øu c·∫ßn)
# -----------------------------
### C√°i n√†y b·ªè nh√© #### a ƒë·ªãnh x·ª≠ l√≠ c√°i n√†y ch·ªâ c√≥ 2 bi·∫øn Indpendent v√† Family th√¥i 
def process_marital_status(df: pd.DataFrame) -> pd.DataFrame:
    """
    X·ª≠ l√Ω marital_status b·∫±ng c√°ch g·ªôp nh√≥m v√† c√¢n b·∫±ng l·∫°i m·∫´u
    """
    # G·ªôp c√°c nh√≥m t∆∞∆°ng t·ª± nh∆∞ng gi·ªØ nguy√™n t√™n c·ªôt marital_status
    marital_mapping = {
        'Single': 'Independent',
        'Married': 'Family',
        'Divorced': 'Independent',
        'Widowed': 'Independent',
        'Separated': 'Independent',
        'Common-Law': 'Independent'
    }
    
    # T·∫°o c·ªôt t·∫°m th·ªùi ƒë·ªÉ l∆∞u nh√≥m
    df['_marital_status_group'] = df['marital_status'].map(marital_mapping)
    
    # T√≠nh to√°n tr·ªçng s·ªë cho t·ª´ng nh√≥m
    marital_weights = {
        'Independent': 1.0,  # Nh√≥m c∆° b·∫£n
        'Family': 1.0       # C√¢n b·∫±ng v·ªõi nh√≥m c∆° b·∫£n
    }
    
    # √Åp d·ª•ng tr·ªçng s·ªë v√†o c·ªôt g·ªëc
    df['marital_status'] = df['_marital_status_group'].map(marital_mapping)
    
    # X√≥a c·ªôt t·∫°m th·ªùi
    df = df.drop('_marital_status_group', axis=1)
    
    return df

def add_derived_features(df: pd.DataFrame) -> pd.DataFrame:
    """Th√™m c√°c t√≠nh nƒÉng ph√°i sinh."""
    # T√≠nh ƒëi·ªÉm ·ªïn ƒë·ªãnh vi·ªác l√†m
    df['employment_stability_score'] = df['employer_tenure_years'] / 30.0
    
    # T√≠nh ƒëi·ªÉm t√≠n d·ª•ng ƒëi·ªÅu ch·ªânh
    df['adjusted_credit_score'] = df['credit_score'] / 850.0
    
    # T√≠nh ƒëi·ªÉm t·ªïng h·ª£p
    df['composite_score'] = (
        (1 - df['dti_ratio']) * 0.3 +
        df['adjusted_credit_score'] * 0.3 +
        (1 - df['delinquencies_30d'] / 10) * 0.2 +
        (1 - df['bankruptcy_flag']) * 0.2
    )
    
    return df


# -----------------------------
# üõ°Ô∏è Rule-based checks cho c√°c features hi·ªán c√≥
# -----------------------------
def rule_based_checks(df: pd.DataFrame) -> None:
    """Ki·ªÉm tra c√°c quy t·∫Øc d·ªØ li·ªáu."""
    # Quy t·∫Øc s·ªë
    numeric_rules = {
        'employer_tenure_years': (0, 32),
        'monthly_net_income': (3600000, 75000000),
        'dti_ratio': (0, 2),
        'credit_score': (427, 898),
        'delinquencies_30d': (0, 10),
        'bankruptcy_flag': (0, 1),
        'income_gap_ratio': (-1, 1),
        'requested_loan_amount': (62964241, 2883967540),  # N·ªõi r·ªông theo d·ªØ li·ªáu th·ª±c t·∫ø
        'tenor_requested': (6, 72)
    }
    
    for col, (min_val, max_val) in numeric_rules.items():
        assert df[col].between(min_val, max_val).all(), \
            f"{col} ph·∫£i n·∫±m trong kho·∫£ng [{min_val}, {max_val}]"
    
    # Quy t·∫Øc ph√¢n lo·∫°i
    categorical_rules = {
        'employment_status': ['Full-Time', 'Part-Time', 'Self-Employed', 'Freelancer', 
                            'Contract', 'Seasonal', 'Unemployed', 'Student', 'Retired'],
        'housing_status': ['Own', 'Rent', 'Mortgage', 'Family', 'Company Dorm', 
                          'Government', 'Other'],
        'loan_purpose_code': ['EDU', 'AGRI', 'CONSOLIDATION', 'HOME', 'TRAVEL', 'AUTO',
                             'MED', 'OTHER', 'BUSS', 'PL', 'RENOVATION', 'CREDIT_CARD']
    }
    
    for col, valid_values in categorical_rules.items():
        assert df[col].isin(valid_values).all(), \
            f"{col} ph·∫£i l√† m·ªôt trong c√°c gi√° tr·ªã: {valid_values}"


# -----------------------------
# üß† Fit encoder & scaler (ch·ªâ d√πng khi training)
# -----------------------------
def fit_transformers(df: pd.DataFrame):
    """Fit c√°c transformer cho categorical v√† numerical features."""
    # Th√™m c√°c feature ph√°i sinh tr∆∞·ªõc khi fit
    df = add_derived_features(df.copy())
    categorical_features = ['employment_status', 'housing_status', 'loan_purpose_code']
    numerical_features = [col for col in df.columns if col not in categorical_features + ['approved']]

    # Fit OneHotEncoder
    ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
    ohe.fit(df[categorical_features])

    # Fit StandardScaler
    scaler = StandardScaler()
    scaler.fit(df[numerical_features])

    return ohe, scaler, categorical_features, numerical_features


# -----------------------------
# üìä D√πng khi training
# -----------------------------
def preprocess_for_training(df: pd.DataFrame, ohe, scaler, categorical_features, numerical_features):
    """Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu cho training."""
    # Th√™m c√°c t√≠nh nƒÉng ph√°i sinh
    df = add_derived_features(df)
    # Ki·ªÉm tra c√°c quy t·∫Øc
    rule_based_checks(df)
    # T√°ch features v√† target
    X = df.drop('approved', axis=1)
    y = df['approved']
    # Transform categorical features
    cat_data = ohe.transform(X[categorical_features])
    cat_df = pd.DataFrame(
        cat_data,
        columns=ohe.get_feature_names_out(categorical_features)
    )
    # Transform numerical features
    # Chuy·ªÉn ƒë·ªïi bankruptcy_flag sang int tr∆∞·ªõc khi transform
    X['bankruptcy_flag'] = X['bankruptcy_flag'].astype(int)
    num_data = scaler.transform(X[numerical_features])
    num_df = pd.DataFrame(
        num_data,
        columns=numerical_features
    )
    # Combine transformed features
    X_processed = pd.concat([cat_df, num_df], axis=1)
    return X_processed.values, y.values, X_processed.columns.tolist()


# -----------------------------
# ‚öôÔ∏è D√πng trong API khi ƒë√£ c√≥ ohe + scaler
# -----------------------------
def preprocess_for_inference(df: pd.DataFrame, ohe: OneHotEncoder, scaler: StandardScaler, feature_cols: list):
    try:
        print("\n=== DEBUG INFO ===")
        print("1. Input DataFrame info:")
        print("Shape:", df.shape)
        print("Columns:", df.columns.tolist())
        print("Dtypes:", df.dtypes)
        
        print("\n2. Required feature_cols:")
        print("Length:", len(feature_cols))
        print("Features:", feature_cols)
        
        df = add_derived_features(df)
        print("\n3. After add_derived_features:")
        print("Shape:", df.shape)
        print("Columns:", df.columns.tolist())
        print("Dtypes:", df.dtypes)
        
        # L·∫•y th·ª© t·ª± numerical features t·ª´ feature_cols
        numerical_features = [col for col in feature_cols if col not in ohe.get_feature_names_out()]
        print("\n4. Numerical features from feature_cols:")
        print("Features:", numerical_features)
        
        cat_cols = [
            'employment_status', 'housing_status', 'loan_purpose_code'
        ]
        
        print("\n5. Column groups:")
        print("Categorical:", cat_cols)
        print("Numerical:", numerical_features)
        
        # Transform categorical features
        print("\n6. Categorical transformation:")
        print("Input shape:", df[cat_cols].shape)
        cat_vals = ohe.transform(df[cat_cols])
        cat_feature_names = ohe.get_feature_names_out(cat_cols)
        print("Output shape:", cat_vals.shape)
        print("Feature names:", cat_feature_names.tolist())
        
        # Transform numerical features
        print("\n7. Numerical transformation:")
        # Chuy·ªÉn ƒë·ªïi bankruptcy_flag sang int tr∆∞·ªõc khi transform
        df['bankruptcy_flag'] = df['bankruptcy_flag'].astype(int)
        # ƒê·∫£m b·∫£o th·ª© t·ª± c√°c c·ªôt gi·ªëng v·ªõi numerical_features
        num_vals = scaler.transform(df[numerical_features]).astype(np.float32)
        num_df = pd.DataFrame(num_vals, columns=numerical_features, index=df.index)
        print("Output shape:", num_vals.shape)
        print("Columns:", num_df.columns.tolist())
        
        # Combine features
        print("\n8. Combining features:")
        # T·∫°o DataFrame tr·ª±c ti·∫øp t·ª´ cat_vals (numpy array)
        cat_df = pd.DataFrame(cat_vals, columns=cat_feature_names, index=df.index)
        X_new = pd.concat([cat_df, num_df], axis=1)
        print("Final shape:", X_new.shape)
        print("Final columns:", X_new.columns.tolist())
        
        # ƒê·∫£m b·∫£o th·ª© t·ª± features gi·ªëng v·ªõi feature_cols
        print("\n9. Reindexing to match feature_cols order:")
        X_new = X_new.reindex(columns=feature_cols)
        print("Final shape:", X_new.shape)
        print("Final columns:", X_new.columns.tolist())
        
        return X_new
        
    except Exception as e:
        print("\n=== ERROR INFO ===")
        print(f"Error type: {type(e).__name__}")
        print(f"Error message: {str(e)}")
        import traceback
        print("\nFull traceback:")
        print(traceback.format_exc())
        raise

def adjust_weights(df: pd.DataFrame) -> pd.DataFrame:
    # Nh√≥m 1: Ng∆∞·ªùi m·ªõi b·∫Øt ƒë·∫ßu (th·ªùi gian l√†m vi·ªác < 3 nƒÉm)
    mask_new = df['employer_tenure_years'] < 3
    df.loc[mask_new, 'composite_score'] *= 1.2  # TƒÉng 20% ƒëi·ªÉm
    
    # Nh√≥m 2: Ng∆∞·ªùi c√≥ thu nh·∫≠p th·∫•p nh∆∞ng ·ªïn ƒë·ªãnh
    mask_stable = (df['monthly_gross_income'] < 30000000) & (df['employer_tenure_years'] > 5)
    df.loc[mask_stable, 'composite_score'] *= 1.15  # TƒÉng 15% ƒëi·ªÉm
    
    # Nh√≥m 3: Ng∆∞·ªùi c√≥ t√†i s·∫£n th·∫ø ch·∫•p
    mask_collateral = df['housing_status'].isin(['Own', 'Mortgage'])
    df.loc[mask_collateral, 'composite_score'] *= 1.1  # TƒÉng 10% ƒëi·ªÉm
    
    return df

def apply_compensation_rules(df: pd.DataFrame) -> pd.DataFrame:
    # Quy t·∫Øc 1: B√π tr·ª´ cho ng∆∞·ªùi c√≥ l·ªãch s·ª≠ thanh to√°n t·ªët
    good_payment = (df['delinquencies_30d'] == 0) & (df['revolving_utilisation'] < 0.3)
    df.loc[good_payment, 'composite_score'] *= 1.15
    
    # Quy t·∫Øc 2: B√π tr·ª´ cho ng∆∞·ªùi c√≥ tr√¨nh ƒë·ªô cao
    high_education = df['educational_level'].isin(['Master', 'MBA', 'Doctorate'])
    df.loc[high_education, 'composite_score'] *= 1.1
    
    # Quy t·∫Øc 3: B√π tr·ª´ cho ng∆∞·ªùi c√≥ v·ªã tr√≠ c√¥ng vi·ªác cao
    high_position = df['position_in_company'].isin(['Director', 'Senior Mgr', 'Owner'])
    df.loc[high_position, 'composite_score'] *= 1.1
    
    return df

def adjust_approval_threshold(df: pd.DataFrame) -> pd.DataFrame:
    # Ng∆∞·ª°ng c∆° b·∫£n
    base_threshold = 0.5
    
    # ƒêi·ªÅu ch·ªânh ng∆∞·ª°ng theo nh√≥m
    df['approval_threshold'] = base_threshold
    
    # Gi·∫£m ng∆∞·ª°ng cho ng∆∞·ªùi m·ªõi b·∫Øt ƒë·∫ßu c√≥ ti·ªÅm nƒÉng
    new_potential = (df['employer_tenure_years'] < 3) & (df['educational_level'].isin(['Master', 'MBA', 'Doctorate']))
    df.loc[new_potential, 'approval_threshold'] *= 0.9
    
    # Gi·∫£m ng∆∞·ª°ng cho ng∆∞·ªùi c√≥ thu nh·∫≠p th·∫•p nh∆∞ng ·ªïn ƒë·ªãnh
    stable_low_income = (df['monthly_gross_income'] < 30000000) & (df['employer_tenure_years'] > 5)
    df.loc[stable_low_income, 'approval_threshold'] *= 0.95
    
    return df

def adjust_employment_weights(df: pd.DataFrame) -> pd.DataFrame:
    """
    ƒêi·ªÅu ch·ªânh tr·ªçng s·ªë d·ª±a tr√™n t√¨nh tr·∫°ng vi·ªác l√†m
    """
    # T·∫°o b·∫£n sao ƒë·ªÉ tr√°nh thay ƒë·ªïi d·ªØ li·ªáu g·ªëc
    df = df.copy()
    
    # ƒêi·ªÅu ch·ªânh tr·ªçng s·ªë cho ng∆∞·ªùi th·∫•t nghi·ªáp
    unemployed_mask = df['employment_status'] == 'Unemployed'
    if unemployed_mask.any():
        # Gi·∫£m x√°c su·∫•t ph√™ duy·ªát cho ng∆∞·ªùi th·∫•t nghi·ªáp
        df.loc[unemployed_mask, 'employment_status_weight'] = 0.3
    
    # ƒêi·ªÅu ch·ªânh tr·ªçng s·ªë cho ng∆∞·ªùi l√†m vi·ªác to√†n th·ªùi gian
    full_time_mask = df['employment_status'] == 'Full-Time'
    if full_time_mask.any():
        df.loc[full_time_mask, 'employment_status_weight'] = 1.0
    
    # ƒêi·ªÅu ch·ªânh tr·ªçng s·ªë cho c√°c tr·∫°ng th√°i kh√°c
    other_mask = ~(unemployed_mask | full_time_mask)
    if other_mask.any():
        df.loc[other_mask, 'employment_status_weight'] = 0.7
    
    return df

def adjust_marital_status_weights(df: pd.DataFrame) -> pd.DataFrame:
    """
    ƒêi·ªÅu ch·ªânh tr·ªçng s·ªë d·ª±a tr√™n t√¨nh tr·∫°ng h√¥n nh√¢n
    """
    # T·∫°o b·∫£n sao ƒë·ªÉ tr√°nh thay ƒë·ªïi d·ªØ li·ªáu g·ªëc
    df = df.copy()
    
    # ƒêi·ªÅu ch·ªânh tr·ªçng s·ªë cho ng∆∞·ªùi ƒë√£ k·∫øt h√¥n
    married_mask = df['marital_status'] == 'Married'
    if married_mask.any():
        # TƒÉng x√°c su·∫•t ph√™ duy·ªát cho ng∆∞·ªùi ƒë√£ k·∫øt h√¥n
        df.loc[married_mask, 'marital_status_weight'] = 1.0
    
    # ƒêi·ªÅu ch·ªânh tr·ªçng s·ªë cho ng∆∞·ªùi ƒë·ªôc th√¢n
    single_mask = df['marital_status'] == 'Single'
    if single_mask.any():
        df.loc[single_mask, 'marital_status_weight'] = 0.8
    
    # ƒêi·ªÅu ch·ªânh tr·ªçng s·ªë cho ng∆∞·ªùi ly h√¥n
    divorced_mask = df['marital_status'] == 'Divorced'
    if divorced_mask.any():
        df.loc[divorced_mask, 'marital_status_weight'] = 0.6
    
    # ƒêi·ªÅu ch·ªânh tr·ªçng s·ªë cho c√°c tr·∫°ng th√°i kh√°c
    other_mask = ~(married_mask | single_mask | divorced_mask)
    if other_mask.any():
        df.loc[other_mask, 'marital_status_weight'] = 0.7
    
    return df

######################### T·∫°o g·ª£i √Ω, l·ª£i khuy√™n ############################################# C√°i n√†y c√≥ th·ªÉ xem t√≠nh h·ª£p v·ªõi b√™n em


def generate_customer_advice(df: pd.DataFrame) -> dict:
    """
    T·∫°o l·ªùi t∆∞ v·∫•n th√¢n thi·ªán cho kh√°ch h√†ng d·ª±a tr√™n h·ªì s∆° c·ªßa h·ªç
    """
    advice = {
        "strengths": [],
        "improvements": [],
        "suggestions": [],
        "next_steps": []
    }
    
    # Ph√¢n t√≠ch ƒëi·ªÉm m·∫°nh
    if df['credit_score'].iloc[0] >= 800:
        advice["strengths"].append("ƒêi·ªÉm t√≠n d·ª•ng c·ªßa b·∫°n r·∫•t t·ªët, ƒë√¢y l√† m·ªôt l·ª£i th·∫ø l·ªõn")
    elif df['credit_score'].iloc[0] >= 700:
        advice["strengths"].append("ƒêi·ªÉm t√≠n d·ª•ng c·ªßa b·∫°n ·ªü m·ª©c kh√° t·ªët")
        
    if df['employer_tenure_years'].iloc[0] >= 5:
        advice["strengths"].append(f"B·∫°n c√≥ {df['employer_tenure_years'].iloc[0]} nƒÉm kinh nghi·ªám l√†m vi·ªác, th·ªÉ hi·ªán s·ª± ·ªïn ƒë·ªãnh t·ªët")
        
    if df['housing_status'].iloc[0] in ['Own', 'Mortgage']:
        advice["strengths"].append("Vi·ªác s·ªü h·ªØu nh√† ri√™ng l√† m·ªôt ƒëi·ªÉm c·ªông v·ªÅ t√†i s·∫£n th·∫ø ch·∫•p")
        
    if df['employment_status'].iloc[0] == 'Full-Time':
        advice["strengths"].append("C√¥ng vi·ªác to√†n th·ªùi gian th·ªÉ hi·ªán s·ª± ·ªïn ƒë·ªãnh trong thu nh·∫≠p")
        
    # Ph√¢n t√≠ch ƒëi·ªÉm c·∫ßn c·∫£i thi·ªán
    if df['delinquencies_30d'].iloc[0] > 0:
        advice["improvements"].append(f"B·∫°n c√≥ {df['delinquencies_30d'].iloc[0]} l·∫ßn ch·∫≠m thanh to√°n trong 30 ng√†y, n√™n c·∫£i thi·ªán l·ªãch s·ª≠ thanh to√°n")
        
    if df['dti_ratio'].iloc[0] > 0.5:
        advice["improvements"].append("T·ª∑ l·ªá n·ª£/thu nh·∫≠p c·ªßa b·∫°n kh√° cao, n√™n gi·∫£m b·ªõt c√°c kho·∫£n n·ª£ hi·ªán t·∫°i")
        
    if df['bankruptcy_flag'].iloc[0] == 1:
        advice["improvements"].append("L·ªãch s·ª≠ ph√° s·∫£n c√≥ th·ªÉ ·∫£nh h∆∞·ªüng ƒë·∫øn kh·∫£ nƒÉng vay v·ªën")
        
    # ƒê·ªÅ xu·∫•t c·∫£i thi·ªán
    if df['monthly_net_income'].iloc[0] < 10000000:
        advice["suggestions"].append("C√≥ th·ªÉ c√¢n nh·∫Øc t√¨m ki·∫øm ngu·ªìn thu nh·∫≠p b·ªï sung")
        
    if df['employer_tenure_years'].iloc[0] < 2:
        advice["suggestions"].append("N√™n duy tr√¨ c√¥ng vi·ªác hi·ªán t·∫°i ƒë·ªÉ th·ªÉ hi·ªán s·ª± ·ªïn ƒë·ªãnh")
        
    if df['housing_status'].iloc[0] in ['Rent', 'Other']:
        advice["suggestions"].append("C√¢n nh·∫Øc vi·ªác s·ªü h·ªØu t√†i s·∫£n ƒë·ªÉ tƒÉng kh·∫£ nƒÉng vay v·ªën")
        
    # H∆∞·ªõng d·∫´n ti·∫øp theo
    advice["next_steps"].append("Chu·∫©n b·ªã ƒë·∫ßy ƒë·ªß c√°c gi·∫•y t·ªù ch·ª©ng minh thu nh·∫≠p v√† t√†i s·∫£n")
    advice["next_steps"].append("C√¢n nh·∫Øc gi·∫£m b·ªõt s·ªë ti·ªÅn vay ho·∫∑c tƒÉng th·ªùi h·∫°n vay ƒë·ªÉ gi·∫£m √°p l·ª±c tr·∫£ n·ª£")
    advice["next_steps"].append("Li√™n h·ªá v·ªõi chuy√™n vi√™n t∆∞ v·∫•n ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£ chi ti·∫øt h∆°n")
    
    return advice
