import sys, os
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

import pandas as pd
import numpy as np
import sqlalchemy
import sklearn
from sqlalchemy import text
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from scipy import sparse

# Use sparse matrices for OneHotEncoder
if sklearn.__version__ >= "1.2":
    ohe = OneHotEncoder(sparse_output=True, handle_unknown='ignore')
else:
    ohe = OneHotEncoder(sparse=True, handle_unknown='ignore')

# -----------------------------
# üì• Load d·ªØ li·ªáu t·ª´ MySQL
# -----------------------------
def load_data():
    df = pd.read_csv("data/loan100.csv")
    print("\nTh√¥ng tin DataFrame:")
    print(f"Shape: {df.shape}")
    print("\nC√°c c·ªôt trong DataFrame:")
    print(df.columns.tolist())
    print("\nM·∫´u d·ªØ li·ªáu (5 d√≤ng ƒë·∫ßu):")
    print(df.head())
    return df


# -----------------------------
# üéØ Sinh th√™m ƒë·∫∑c tr∆∞ng m·ªõi (n·∫øu c·∫ßn)
# -----------------------------
### C√°i n√†y b·ªè nh√© #### a ƒë·ªãnh x·ª≠ l√≠ c√°i n√†y ch·ªâ c√≥ 2 bi·∫øn Indpendent v√† Family th√¥i 
def process_marital_status(df: pd.DataFrame) -> pd.DataFrame:
    """
    X·ª≠ l√Ω marital_status b·∫±ng c√°ch g·ªôp nh√≥m v√† c√¢n b·∫±ng l·∫°i m·∫´u
    """
    # G·ªôp c√°c nh√≥m t∆∞∆°ng t·ª± nh∆∞ng gi·ªØ nguy√™n t√™n c·ªôt marital_status
    marital_mapping = {
        'Single': 'Independent',
        'Married': 'Family',
        'Divorced': 'Independent',
        'Widowed': 'Independent',
        'Separated': 'Independent',
        'Common-Law': 'Independent'
    }
    
    # T·∫°o c·ªôt t·∫°m th·ªùi ƒë·ªÉ l∆∞u nh√≥m
    df['_marital_status_group'] = df['marital_status'].map(marital_mapping)
    
    # T√≠nh to√°n tr·ªçng s·ªë cho t·ª´ng nh√≥m
    marital_weights = {
        'Independent': 1.0,  # Nh√≥m c∆° b·∫£n
        'Family': 1.0       # C√¢n b·∫±ng v·ªõi nh√≥m c∆° b·∫£n
    }
    
    # √Åp d·ª•ng tr·ªçng s·ªë v√†o c·ªôt g·ªëc
    df['marital_status'] = df['_marital_status_group'].map(marital_mapping)
    
    # X√≥a c·ªôt t·∫°m th·ªùi
    df = df.drop('_marital_status_group', axis=1)
    
    return df

def add_derived_features(df: pd.DataFrame) -> pd.DataFrame:
    # T√≠nh th√™m ƒêi·ªÉm ·ªïn ƒë·ªãnh vi·ªác l√†m (ch·ªâ d√πng employer_tenure_years v√¨ address_tenure_years kh√¥ng c√≤n)
    df['employment_stability_score'] = df['employer_tenure_years'] * 10
    
    # T√≠nh th√™m ƒêi·ªÉm t√≠n d·ª•ng ƒëi·ªÅu ch·ªânh (ch·ªâ d√πng credit_score v√¨ active_trade_lines kh√¥ng c√≤n)
    df['adjusted_credit_score'] = df['credit_score'].astype(float)
    
    # T√≠nh th√™m ƒêi·ªÉm t·ªïng h·ª£p (ch·ªâ d√πng c√°c features c√≥ s·∫µn)
    df['composite_score'] = (
        df['adjusted_credit_score'] * 0.4 +
        df['employment_stability_score'] * 0.3 +
        (1 - df['dti_ratio']) * 0.3  # S·ª≠ d·ª•ng dti_ratio thay cho savings_ratio
    )
    
    return df


# -----------------------------
# üõ°Ô∏è Rule-based checks cho c√°c features hi·ªán c√≥
# -----------------------------
def rule_based_checks(df):
    # Numeric rules
    numeric_rules = {
        'employer_tenure_years': (0, 30, "employer_tenure_years ph·∫£i trong kho·∫£ng [0, 30]"),
        'monthly_net_income': (3800000, 71100000, "monthly_net_income ph·∫£i trong kho·∫£ng [3.8M, 71.1M]"),
        'dti_ratio': (0, 1.5, "dti_ratio ph·∫£i trong kho·∫£ng [0, 1.5]"),
        'credit_score': (300, 850, "credit_score ph·∫£i trong kho·∫£ng [300, 850]"),
        'delinquencies_30d': (0, 4, "delinquencies_30d ph·∫£i trong kho·∫£ng [0, 4]"),
        'industry_unemployment_rate': (0, 0.15, "industry_unemployment_rate ph·∫£i trong kho·∫£ng [0, 0.15]"),
        'income_gap_ratio': (-0.3, 0.3, "income_gap_ratio ph·∫£i trong kho·∫£ng [-0.3, 0.3]")
    }
    
    for col, (min_val, max_val, msg) in numeric_rules.items():
        assert (df[col] >= min_val).all() and (df[col] <= max_val).all(), msg
    
    # Categorical rules
    categorical_rules = {
        'employment_status': ['Full-Time', 'Part-Time', 'Self-Employed', 'Freelancer', 'Contract', 'Seasonal', 'Unemployed', 'Retired', 'Student'],
        'housing_status': ['Own', 'Rent', 'Mortgage', 'Family', 'Company Dorm', 'Government', 'Other']
    }
    
    for col, valid_values in categorical_rules.items():
        assert df[col].isin(valid_values).all(), f"{col} ph·∫£i l√† m·ªôt trong c√°c gi√° tr·ªã: {valid_values}"
    
    # Boolean rules
    boolean_rules = {
        'bankruptcy_flag': [0, 1]
    }
    
    for col, valid_values in boolean_rules.items():
        assert df[col].isin(valid_values).all(), f"{col} ph·∫£i l√† m·ªôt trong c√°c gi√° tr·ªã: {valid_values}"
    
    return df


# -----------------------------
# üß† Fit encoder & scaler (ch·ªâ d√πng khi training)
# -----------------------------
def fit_transformers(df: pd.DataFrame):
    df = add_derived_features(df)
    df = rule_based_checks(df)
    
    cat_cols = [
        'employment_status', 'housing_status'
    ]
    num_cols = [
        'employer_tenure_years', 'monthly_net_income', 'dti_ratio', 'credit_score',
        'delinquencies_30d', 'industry_unemployment_rate', 'income_gap_ratio'
    ]
    bool_cols = ['bankruptcy_flag']
    
    ohe = OneHotEncoder(sparse_output=True, handle_unknown='ignore')
    ohe.fit(df[cat_cols])
    scaler = StandardScaler()
    scaler.fit(df[num_cols])
    return ohe, scaler


# -----------------------------
# üìä D√πng khi training
# -----------------------------
def preprocess_for_training(df: pd.DataFrame, ohe: OneHotEncoder, scaler: StandardScaler):
    df = add_derived_features(df)
    df = rule_based_checks(df)
    
    cat_cols = [
        'employment_status', 'housing_status'
    ]
    num_cols = [
        'employer_tenure_years', 'monthly_net_income', 'dti_ratio', 'credit_score',
        'delinquencies_30d', 'industry_unemployment_rate', 'income_gap_ratio'
    ]
    bool_cols = ['bankruptcy_flag']
    
    # Convert boolean to int8
    for col in bool_cols:
        df[col] = df[col].astype(np.int8)
    
    # Transform categorical features to sparse matrix
    cat_vals = ohe.transform(df[cat_cols])
    cat_feature_names = ohe.get_feature_names_out(cat_cols)
    
    # Transform numeric features and convert to float32 to save memory
    num_vals = scaler.transform(df[num_cols]).astype(np.float32)
    num_df = pd.DataFrame(num_vals, columns=num_cols, index=df.index)
    
    # Convert boolean features to int8
    bool_df = df[bool_cols].astype(np.int8)
    
    # Combine all features
    X = sparse.hstack([sparse.csr_matrix(num_df), sparse.csr_matrix(bool_df), cat_vals])
    
    # Create feature names list
    feature_names = num_cols + bool_cols + cat_feature_names.tolist()
    
    # Check if approved column exists
    if 'approved' not in df.columns:
        print("\nC√°c c·ªôt hi·ªán c√≥ trong DataFrame:")
        print(df.columns.tolist())
        print("\nVui l√≤ng ƒë·∫£m b·∫£o c·ªôt 'approved' t·ªìn t·∫°i trong d·ªØ li·ªáu ƒë·∫ßu v√†o.")
        raise ValueError("C·ªôt 'approved' kh√¥ng t·ªìn t·∫°i trong d·ªØ li·ªáu. Vui l√≤ng ki·ªÉm tra l·∫°i d·ªØ li·ªáu ƒë·∫ßu v√†o.")
    
    y = df['approved']
    if y.isna().any():
        print("\nS·ªë l∆∞·ª£ng gi√° tr·ªã NA trong c·ªôt 'approved':", y.isna().sum())
        raise ValueError("C·ªôt 'approved' ch·ª©a gi√° tr·ªã NA. Vui l√≤ng ki·ªÉm tra v√† x·ª≠ l√Ω d·ªØ li·ªáu thi·∫øu.")
    
    # Convert approved to int8 (0/1)
    y = y.astype(np.int8)
    
    return X, y, feature_names


# -----------------------------
# ‚öôÔ∏è D√πng trong API khi ƒë√£ c√≥ ohe + scaler
# -----------------------------
def preprocess_for_inference(df: pd.DataFrame, ohe: OneHotEncoder, scaler: StandardScaler, feature_cols: list):
    df = add_derived_features(df)
    df = rule_based_checks(df)
    
    cat_cols = [
        'employment_status', 'housing_status'
    ]
    num_cols = [
        'employer_tenure_years', 'monthly_net_income', 'dti_ratio', 'credit_score',
        'delinquencies_30d', 'industry_unemployment_rate', 'income_gap_ratio'
    ]
    bool_cols = ['bankruptcy_flag']
    
    # Convert boolean to int8
    for col in bool_cols:
        df[col] = df[col].astype(np.int8)
    
    # Transform categorical features to sparse matrix
    cat_vals = ohe.transform(df[cat_cols])
    cat_feature_names = ohe.get_feature_names_out(cat_cols)
    
    # Transform numeric features and convert to float32
    num_vals = scaler.transform(df[num_cols]).astype(np.float32)
    num_df = pd.DataFrame(num_vals, columns=num_cols, index=df.index)
    
    # Convert boolean features to int8
    bool_df = df[bool_cols].astype(np.int8)
    
    # Combine all features
    X_new = sparse.hstack([sparse.csr_matrix(num_df), sparse.csr_matrix(bool_df), cat_vals])
    
    # Create feature names list
    feature_names = num_cols + bool_cols + cat_feature_names.tolist()
    
    # Convert to dense matrix only for the required features
    X_new = X_new.todense()
    X_new = pd.DataFrame(X_new, columns=feature_names)
    X_new = X_new[feature_cols]
    
    return X_new

def adjust_weights(df: pd.DataFrame) -> pd.DataFrame:
    # Nh√≥m 1: Ng∆∞·ªùi m·ªõi b·∫Øt ƒë·∫ßu (th·ªùi gian l√†m vi·ªác < 3 nƒÉm)
    mask_new = df['employer_tenure_years'] < 3
    df.loc[mask_new, 'composite_score'] *= 1.2  # TƒÉng 20% ƒëi·ªÉm
    
    # Nh√≥m 2: Ng∆∞·ªùi c√≥ thu nh·∫≠p th·∫•p nh∆∞ng ·ªïn ƒë·ªãnh
    mask_stable = (df['monthly_gross_income'] < 30000000) & (df['employer_tenure_years'] > 5)
    df.loc[mask_stable, 'composite_score'] *= 1.15  # TƒÉng 15% ƒëi·ªÉm
    
    # Nh√≥m 3: Ng∆∞·ªùi c√≥ t√†i s·∫£n th·∫ø ch·∫•p
    mask_collateral = df['housing_status'].isin(['Own', 'Mortgage'])
    df.loc[mask_collateral, 'composite_score'] *= 1.1  # TƒÉng 10% ƒëi·ªÉm
    
    return df

def apply_compensation_rules(df: pd.DataFrame) -> pd.DataFrame:
    # Quy t·∫Øc 1: B√π tr·ª´ cho ng∆∞·ªùi c√≥ l·ªãch s·ª≠ thanh to√°n t·ªët
    good_payment = (df['delinquencies_30d'] == 0) & (df['revolving_utilisation'] < 0.3)
    df.loc[good_payment, 'composite_score'] *= 1.15
    
    # Quy t·∫Øc 2: B√π tr·ª´ cho ng∆∞·ªùi c√≥ tr√¨nh ƒë·ªô cao
    high_education = df['educational_level'].isin(['Master', 'MBA', 'Doctorate'])
    df.loc[high_education, 'composite_score'] *= 1.1
    
    # Quy t·∫Øc 3: B√π tr·ª´ cho ng∆∞·ªùi c√≥ v·ªã tr√≠ c√¥ng vi·ªác cao
    high_position = df['position_in_company'].isin(['Director', 'Senior Mgr', 'Owner'])
    df.loc[high_position, 'composite_score'] *= 1.1
    
    return df

def adjust_approval_threshold(df: pd.DataFrame) -> pd.DataFrame:
    # Ng∆∞·ª°ng c∆° b·∫£n
    base_threshold = 0.5
    
    # ƒêi·ªÅu ch·ªânh ng∆∞·ª°ng theo nh√≥m
    df['approval_threshold'] = base_threshold
    
    # Gi·∫£m ng∆∞·ª°ng cho ng∆∞·ªùi m·ªõi b·∫Øt ƒë·∫ßu c√≥ ti·ªÅm nƒÉng
    new_potential = (df['employer_tenure_years'] < 3) & (df['educational_level'].isin(['Master', 'MBA', 'Doctorate']))
    df.loc[new_potential, 'approval_threshold'] *= 0.9
    
    # Gi·∫£m ng∆∞·ª°ng cho ng∆∞·ªùi c√≥ thu nh·∫≠p th·∫•p nh∆∞ng ·ªïn ƒë·ªãnh
    stable_low_income = (df['monthly_gross_income'] < 30000000) & (df['employer_tenure_years'] > 5)
    df.loc[stable_low_income, 'approval_threshold'] *= 0.95
    
    return df

def adjust_employment_weights(df: pd.DataFrame) -> pd.DataFrame:
    """
    ƒêi·ªÅu ch·ªânh tr·ªçng s·ªë d·ª±a tr√™n t√¨nh tr·∫°ng vi·ªác l√†m
    """
    # T·∫°o b·∫£n sao ƒë·ªÉ tr√°nh thay ƒë·ªïi d·ªØ li·ªáu g·ªëc
    df = df.copy()
    
    # ƒêi·ªÅu ch·ªânh tr·ªçng s·ªë cho ng∆∞·ªùi th·∫•t nghi·ªáp
    unemployed_mask = df['employment_status'] == 'Unemployed'
    if unemployed_mask.any():
        # Gi·∫£m x√°c su·∫•t ph√™ duy·ªát cho ng∆∞·ªùi th·∫•t nghi·ªáp
        df.loc[unemployed_mask, 'employment_status_weight'] = 0.3
    
    # ƒêi·ªÅu ch·ªânh tr·ªçng s·ªë cho ng∆∞·ªùi l√†m vi·ªác to√†n th·ªùi gian
    full_time_mask = df['employment_status'] == 'Full-Time'
    if full_time_mask.any():
        df.loc[full_time_mask, 'employment_status_weight'] = 1.0
    
    # ƒêi·ªÅu ch·ªânh tr·ªçng s·ªë cho c√°c tr·∫°ng th√°i kh√°c
    other_mask = ~(unemployed_mask | full_time_mask)
    if other_mask.any():
        df.loc[other_mask, 'employment_status_weight'] = 0.7
    
    return df

def adjust_marital_status_weights(df: pd.DataFrame) -> pd.DataFrame:
    """
    ƒêi·ªÅu ch·ªânh tr·ªçng s·ªë d·ª±a tr√™n t√¨nh tr·∫°ng h√¥n nh√¢n
    """
    # T·∫°o b·∫£n sao ƒë·ªÉ tr√°nh thay ƒë·ªïi d·ªØ li·ªáu g·ªëc
    df = df.copy()
    
    # ƒêi·ªÅu ch·ªânh tr·ªçng s·ªë cho ng∆∞·ªùi ƒë√£ k·∫øt h√¥n
    married_mask = df['marital_status'] == 'Married'
    if married_mask.any():
        # TƒÉng x√°c su·∫•t ph√™ duy·ªát cho ng∆∞·ªùi ƒë√£ k·∫øt h√¥n
        df.loc[married_mask, 'marital_status_weight'] = 1.0
    
    # ƒêi·ªÅu ch·ªânh tr·ªçng s·ªë cho ng∆∞·ªùi ƒë·ªôc th√¢n
    single_mask = df['marital_status'] == 'Single'
    if single_mask.any():
        df.loc[single_mask, 'marital_status_weight'] = 0.8
    
    # ƒêi·ªÅu ch·ªânh tr·ªçng s·ªë cho ng∆∞·ªùi ly h√¥n
    divorced_mask = df['marital_status'] == 'Divorced'
    if divorced_mask.any():
        df.loc[divorced_mask, 'marital_status_weight'] = 0.6
    
    # ƒêi·ªÅu ch·ªânh tr·ªçng s·ªë cho c√°c tr·∫°ng th√°i kh√°c
    other_mask = ~(married_mask | single_mask | divorced_mask)
    if other_mask.any():
        df.loc[other_mask, 'marital_status_weight'] = 0.7
    
    return df

######################### T·∫°o g·ª£i √Ω, l·ª£i khuy√™n ############################################# C√°i n√†y c√≥ th·ªÉ xem t√≠nh h·ª£p v·ªõi b√™n em


def generate_customer_advice(df: pd.DataFrame) -> dict:
    """
    T·∫°o l·ªùi t∆∞ v·∫•n th√¢n thi·ªán cho kh√°ch h√†ng d·ª±a tr√™n h·ªì s∆° c·ªßa h·ªç
    """
    advice = {
        "strengths": [],
        "improvements": [],
        "suggestions": [],
        "next_steps": []
    }
    
    # Ph√¢n t√≠ch ƒëi·ªÉm m·∫°nh
    if df['credit_score'].iloc[0] >= 800:
        advice["strengths"].append("ƒêi·ªÉm t√≠n d·ª•ng c·ªßa b·∫°n r·∫•t t·ªët, ƒë√¢y l√† m·ªôt l·ª£i th·∫ø l·ªõn")
    elif df['credit_score'].iloc[0] >= 700:
        advice["strengths"].append("ƒêi·ªÉm t√≠n d·ª•ng c·ªßa b·∫°n ·ªü m·ª©c kh√° t·ªët")
        
    if df['employer_tenure_years'].iloc[0] >= 5:
        advice["strengths"].append(f"B·∫°n c√≥ {df['employer_tenure_years'].iloc[0]} nƒÉm kinh nghi·ªám l√†m vi·ªác, th·ªÉ hi·ªán s·ª± ·ªïn ƒë·ªãnh t·ªët")
        
    if df['educational_level'].iloc[0] in ['Master', 'MBA', 'Doctorate']:
        advice["strengths"].append(f"Tr√¨nh ƒë·ªô {df['educational_level'].iloc[0]} c·ªßa b·∫°n l√† m·ªôt ƒëi·ªÉm c·ªông l·ªõn")
        
    if df['position_in_company'].iloc[0] in ['Director', 'Senior Mgr', 'Owner']:
        advice["strengths"].append(f"V·ªã tr√≠ {df['position_in_company'].iloc[0]} th·ªÉ hi·ªán nƒÉng l·ª±c v√† tr√°ch nhi·ªám cao")
        
    if df['housing_status'].iloc[0] in ['Own', 'Mortgage']:
        advice["strengths"].append("Vi·ªác s·ªü h·ªØu nh√† ri√™ng l√† m·ªôt ƒëi·ªÉm c·ªông v·ªÅ t√†i s·∫£n th·∫ø ch·∫•p")
        
    # Ph√¢n t√≠ch ƒëi·ªÉm c·∫ßn c·∫£i thi·ªán
    if df['active_trade_lines'].iloc[0] < 5:
        advice["improvements"].append("L·ªãch s·ª≠ t√≠n d·ª•ng c·ªßa b·∫°n c√≤n kh√° m·ªèng, n√™n x√¢y d·ª±ng th√™m c√°c m·ªëi quan h·ªá t√≠n d·ª•ng")
        
    if df['revolving_utilisation'].iloc[0] > 0.5:
        advice["improvements"].append("T·ª∑ l·ªá s·ª≠ d·ª•ng h·∫°n m·ª©c t√≠n d·ª•ng c·ªßa b·∫°n kh√° cao, n√™n gi·∫£m b·ªõt")
        
    if df['dti_ratio'].iloc[0] > 0.5:
        advice["improvements"].append("T·ª∑ l·ªá n·ª£/thu nh·∫≠p c·ªßa b·∫°n kh√° cao, n√™n gi·∫£m b·ªõt c√°c kho·∫£n n·ª£ hi·ªán t·∫°i")
        
    # ƒê·ªÅ xu·∫•t c·∫£i thi·ªán
    if df['active_trade_lines'].iloc[0] < 5:
        advice["suggestions"].append("C√¢n nh·∫Øc m·ªü th√™m 1-2 th·∫ª t√≠n d·ª•ng v√† s·ª≠ d·ª•ng c√≥ tr√°ch nhi·ªám")
        
    if df['monthly_gross_income'].iloc[0] < 30000000:
        advice["suggestions"].append("C√≥ th·ªÉ c√¢n nh·∫Øc t√¨m ki·∫øm ngu·ªìn thu nh·∫≠p b·ªï sung")
        
    if df['savings_ratio'].iloc[0] < 0.2:
        advice["suggestions"].append("N√™n tƒÉng t·ª∑ l·ªá ti·∫øt ki·ªám l√™n √≠t nh·∫•t 20% thu nh·∫≠p")
        
    # H∆∞·ªõng d·∫´n ti·∫øp theo
    advice["next_steps"].append("Chu·∫©n b·ªã ƒë·∫ßy ƒë·ªß c√°c gi·∫•y t·ªù ch·ª©ng minh thu nh·∫≠p v√† t√†i s·∫£n")
    advice["next_steps"].append("C√¢n nh·∫Øc gi·∫£m b·ªõt s·ªë ti·ªÅn vay ho·∫∑c tƒÉng th·ªùi h·∫°n vay ƒë·ªÉ gi·∫£m √°p l·ª±c tr·∫£ n·ª£")
    advice["next_steps"].append("Li√™n h·ªá v·ªõi chuy√™n vi√™n t∆∞ v·∫•n ƒë·ªÉ ƒë∆∞·ª£c h·ªó tr·ª£ chi ti·∫øt h∆°n")
    
    return advice
